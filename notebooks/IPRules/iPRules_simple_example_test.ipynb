{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPRules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets._base import load_csv_data\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "  cap_shape cap_surface cap_color bruises3F odor gill_attachment gill_spacing  \\\n0         x           s         n         t    p               f            c   \n1         x           s         y         t    a               f            c   \n2         b           s         w         t    l               f            c   \n3         x           y         w         t    p               f            c   \n4         x           s         g         f    n               f            w   \n\n  gill_size gill_color stalk_shape  ... stalk_color_above_ring  \\\n0         n          k           e  ...                      w   \n1         b          k           e  ...                      w   \n2         b          n           e  ...                      w   \n3         n          n           e  ...                      w   \n4         b          k           t  ...                      w   \n\n  stalk_color_below_ring veil_type veil_color ring_number ring_type  \\\n0                      w         p          w           o         p   \n1                      w         p          w           o         p   \n2                      w         p          w           o         p   \n3                      w         p          w           o         p   \n4                      w         p          w           o         e   \n\n  spore_print_color population habitat target_value  \n0                 k          s       u            1  \n1                 n          n       g            0  \n2                 n          n       m            0  \n3                 k          s       u            1  \n4                 n          a       g            0  \n\n[5 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cap_shape</th>\n      <th>cap_surface</th>\n      <th>cap_color</th>\n      <th>bruises3F</th>\n      <th>odor</th>\n      <th>gill_attachment</th>\n      <th>gill_spacing</th>\n      <th>gill_size</th>\n      <th>gill_color</th>\n      <th>stalk_shape</th>\n      <th>...</th>\n      <th>stalk_color_above_ring</th>\n      <th>stalk_color_below_ring</th>\n      <th>veil_type</th>\n      <th>veil_color</th>\n      <th>ring_number</th>\n      <th>ring_type</th>\n      <th>spore_print_color</th>\n      <th>population</th>\n      <th>habitat</th>\n      <th>target_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>x</td>\n      <td>s</td>\n      <td>n</td>\n      <td>t</td>\n      <td>p</td>\n      <td>f</td>\n      <td>c</td>\n      <td>n</td>\n      <td>k</td>\n      <td>e</td>\n      <td>...</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>k</td>\n      <td>s</td>\n      <td>u</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>x</td>\n      <td>s</td>\n      <td>y</td>\n      <td>t</td>\n      <td>a</td>\n      <td>f</td>\n      <td>c</td>\n      <td>b</td>\n      <td>k</td>\n      <td>e</td>\n      <td>...</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>n</td>\n      <td>n</td>\n      <td>g</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>b</td>\n      <td>s</td>\n      <td>w</td>\n      <td>t</td>\n      <td>l</td>\n      <td>f</td>\n      <td>c</td>\n      <td>b</td>\n      <td>n</td>\n      <td>e</td>\n      <td>...</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>n</td>\n      <td>n</td>\n      <td>m</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>x</td>\n      <td>y</td>\n      <td>w</td>\n      <td>t</td>\n      <td>p</td>\n      <td>f</td>\n      <td>c</td>\n      <td>n</td>\n      <td>n</td>\n      <td>e</td>\n      <td>...</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>p</td>\n      <td>k</td>\n      <td>s</td>\n      <td>u</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>x</td>\n      <td>s</td>\n      <td>g</td>\n      <td>f</td>\n      <td>n</td>\n      <td>f</td>\n      <td>w</td>\n      <td>b</td>\n      <td>k</td>\n      <td>t</td>\n      <td>...</td>\n      <td>w</td>\n      <td>w</td>\n      <td>p</td>\n      <td>w</td>\n      <td>o</td>\n      <td>e</td>\n      <td>n</td>\n      <td>a</td>\n      <td>g</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 23 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "#iris\n",
    "#dataset = load_iris()\n",
    "target_value_name = 'class'\n",
    "\n",
    "# Mushrooms\n",
    "filename = 'mushrooms'\n",
    "target_true = 'p'\n",
    "target_false = 'e'\n",
    "test_size = 0.33\n",
    "min_number_class_per_node = 3\n",
    "\n",
    "\n",
    "data_file_name = f'../../data/{filename}.csv'\n",
    "pandas_dataset = pd.read_csv(data_file_name)\n",
    "\n",
    "pandas_dataset.columns = [sub.replace('%', '') for sub in pandas_dataset.columns]\n",
    "target_value_name = pandas_dataset.columns[-1]\n",
    "\n",
    "pandas_dataset[target_value_name] = pandas_dataset[target_value_name].map({target_false:0,target_true:1})\n",
    "\n",
    "pandas_dataset.columns = [sub.replace('-', '_').replace(' ', '').replace('class', 'target_value') for sub in pandas_dataset.columns]\n",
    "target_value_name = pandas_dataset.columns[-1]\n",
    "feature_names = pandas_dataset.columns[0:-1]\n",
    "\n",
    "\n",
    "#dataset.feature_names = [sub.replace(' ', '').replace('(cm)', '') for sub in dataset.feature_names]\n",
    "\n",
    "pandas_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   cap_shape_b  cap_shape_c  cap_shape_f  cap_shape_k  cap_shape_s  \\\n0          0.0          0.0          0.0          0.0          0.0   \n1          0.0          0.0          0.0          0.0          0.0   \n2          1.0          0.0          0.0          0.0          0.0   \n3          0.0          0.0          0.0          0.0          0.0   \n4          0.0          0.0          0.0          0.0          0.0   \n\n   cap_shape_x  cap_surface_f  cap_surface_g  cap_surface_s  cap_surface_y  \\\n0          1.0            0.0            0.0            1.0            0.0   \n1          1.0            0.0            0.0            1.0            0.0   \n2          0.0            0.0            0.0            1.0            0.0   \n3          1.0            0.0            0.0            0.0            1.0   \n4          1.0            0.0            0.0            1.0            0.0   \n\n   ...  population_v  population_y  habitat_d  habitat_g  habitat_l  \\\n0  ...           0.0           0.0        0.0        0.0        0.0   \n1  ...           0.0           0.0        0.0        1.0        0.0   \n2  ...           0.0           0.0        0.0        0.0        0.0   \n3  ...           0.0           0.0        0.0        0.0        0.0   \n4  ...           0.0           0.0        0.0        1.0        0.0   \n\n   habitat_m  habitat_p  habitat_u  habitat_w  target_value  \n0        0.0        0.0        1.0        0.0             1  \n1        0.0        0.0        0.0        0.0             0  \n2        1.0        0.0        0.0        0.0             0  \n3        0.0        0.0        1.0        0.0             1  \n4        0.0        0.0        0.0        0.0             0  \n\n[5 rows x 118 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>cap_shape_b</th>\n      <th>cap_shape_c</th>\n      <th>cap_shape_f</th>\n      <th>cap_shape_k</th>\n      <th>cap_shape_s</th>\n      <th>cap_shape_x</th>\n      <th>cap_surface_f</th>\n      <th>cap_surface_g</th>\n      <th>cap_surface_s</th>\n      <th>cap_surface_y</th>\n      <th>...</th>\n      <th>population_v</th>\n      <th>population_y</th>\n      <th>habitat_d</th>\n      <th>habitat_g</th>\n      <th>habitat_l</th>\n      <th>habitat_m</th>\n      <th>habitat_p</th>\n      <th>habitat_u</th>\n      <th>habitat_w</th>\n      <th>target_value</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 118 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def one_hot_encode_dataframe(data, feature_names):\n",
    "    enc = OneHotEncoder(sparse_output=False)\n",
    "    encoded_array = enc.fit_transform(data.loc[:,feature_names])\n",
    "    encoded_feature_names = enc.get_feature_names_out()\n",
    "    df_encoded = pd.DataFrame(encoded_array,columns=encoded_feature_names)\n",
    "    encoded_pandas_dataset = pd.concat([df_encoded, data],axis=1)\n",
    "    encoded_pandas_dataset.drop(labels= feature_names,axis=1,inplace=True)\n",
    "    return encoded_pandas_dataset, encoded_feature_names\n",
    "\n",
    "encoded_pandas_dataset, encoded_feature_names = one_hot_encode_dataframe(pandas_dataset, feature_names)\n",
    "encoded_pandas_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pandas_dataset.shape)\n",
    "\n",
    "# One hot encoding + not doing anything in the rest\n",
    "#ct = make_column_transformer(\n",
    "#    (OneHotEncoder(), feature_names),\n",
    "#    n_jobs=3,\n",
    "#    remainder='passthrough',\n",
    "#    sparse_threshold=0)\n",
    "\n",
    "#pandas_dataset_encoded = ct.fit_transform(pandas_dataset).T\n",
    "\n",
    "#print(pandas_dataset_encoded[0])\n",
    "\n",
    "#column_names = (ct.named_transformers_[\"onehotencoder\"].get_feature_names_out().tolist()\n",
    "#               + [target_value_name])\n",
    "\n",
    "#encoded_dataset = pd.DataFrame(pandas_dataset_encoded, column_names)\n",
    "\n",
    "#encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_pandas_dataset[encoded_feature_names]\n",
    "y = encoded_pandas_dataset[target_value_name]\n",
    "\n",
    "encoded_dataset = Bunch(\n",
    "        data=X.to_numpy(),\n",
    "        target=y.to_numpy(),\n",
    "        target_names=target_value_name,\n",
    "        feature_names=X.columns\n",
    ")\n",
    "\n",
    "#X_display = pandas_dataset.drop([target_value_name], axis=1)\n",
    "#y_display = pandas_dataset[target_value_name]\n",
    "\n",
    "#encoded_pandas_dataset = pd.DataFrame(data= np.c_[dataset['data'], dataset['target']], columns= list(dataset['feature_names']) + ['target'])\n",
    "#encoded_pandas_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sizes (without target):\n",
      "Original size (8124, 117)\n",
      "Train size (5443, 117)\n",
      "Test size (2681, 117)\n"
     ]
    }
   ],
   "source": [
    "#Define dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_dataset.data, encoded_dataset.target, test_size=test_size, random_state=1)\n",
    "encoded_train_pandas_dataset = pd.DataFrame(data= np.c_[X_train, y_train], columns= list(encoded_dataset['feature_names']) + [target_value_name])\n",
    "encoded_test_pandas_dataset = pd.DataFrame(data= np.c_[X_test, y_test], columns= list(encoded_dataset['feature_names']) + [target_value_name])\n",
    "print()\n",
    "print('Sizes (without target):')\n",
    "print(f'Original size {encoded_dataset.data.shape}')\n",
    "print(f'Train size {X_train.shape}')\n",
    "print(f'Test size {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, make_scorer, recall_score, accuracy_score\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "# Define scorer\n",
    "ensemble = XGBRegressor()\n",
    "ensemble.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iPRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from iPRules.iPRules import iPRules\n",
    "\n",
    "ensemble\n",
    "\n",
    "# initialize\n",
    "tree = iPRules(\n",
    "                base_ensemble=ensemble,\n",
    "                feature_names=encoded_dataset.feature_names,\n",
    "                target_value_name = encoded_dataset.target_names,\n",
    "                chi_square_probability = 0.95,\n",
    "                scale_feature_coefficient = 0.85,\n",
    "                min_number_class_per_node = min_number_class_per_node\n",
    "            )\n",
    "\n",
    "# Fit model\n",
    "tree.fit(encoded_train_pandas_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Divide las combinaciones en si el patrÃ³n lo muestran en supervivencia o fallecimiento.\n",
    "negative_categorized_rules, positive_categorized_rules = tree.categorize_patterns(encoded_train_pandas_dataset, 0.9)\n",
    "\n",
    "print(len(negative_categorized_rules))\n",
    "print(len(positive_categorized_rules))\n",
    "\n",
    "print(f'Negative Rules {len(negative_categorized_rules)} ')\n",
    "sum_total = 0\n",
    "sum_specific = 0\n",
    "all_rules = []\n",
    "for rule, number_specific_case, number_total in negative_categorized_rules:\n",
    "    sum_total += number_total\n",
    "    sum_specific += number_specific_case\n",
    "    all_rules += [rule]\n",
    "    print(f'{rule} \\n')\n",
    "\n",
    "print(f'Positive Rules {len(positive_categorized_rules)} ')\n",
    "for rule, number_specific_case, number_total in positive_categorized_rules:\n",
    "    sum_total += number_total\n",
    "    sum_specific += number_specific_case\n",
    "    all_rules += [rule]\n",
    "    print(f'{rule} \\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sortedList = sorted(all_rules)\n",
    "print(f' Rules {len(sortedList)} ')\n",
    "for rules in sortedList:\n",
    "    print(f'{rules} \\n')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "y_pred_test = ensemble.predict(X_test)\n",
    "accuracy = metrics.accuracy_score(y_test, y_pred_test)\n",
    "#Returns death and survival patterns where there's a % of the total cases of that specific type.\n",
    "\n",
    "\n",
    "negative_acc = 0\n",
    "negative_total = 0\n",
    "\n",
    "positive_acc = 0\n",
    "positive_total = 0\n",
    "\n",
    "data_file_name = f'../../data/{filename}_combinations_negatives.csv'\n",
    "\n",
    "for pattern in negative_categorized_rules:\n",
    "    negative_acc += pattern[1]\n",
    "    negative_total += pattern[2]\n",
    "\n",
    "for pattern in positive_categorized_rules:\n",
    "    positive_acc += pattern[1]\n",
    "    positive_total += pattern[2]\n",
    "\n",
    "\n",
    "with open(f'../../data/{filename}_combinations_negatives.csv','w',encoding='UTF8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Combinacion','Casos_encontrados','Casos_totales'])\n",
    "    for pattern in negative_categorized_rules:\n",
    "        writer.writerow(pattern)\n",
    "    file.close()\n",
    "\n",
    "with open(f'../../data/{filename}_combinations_positives.csv','w',encoding='UTF8') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow(['Combinacion','Casos_encontrados','Casos_totales'])\n",
    "    for pattern in positive_categorized_rules:\n",
    "        writer.writerow(pattern)\n",
    "    file.close()\n",
    "\n",
    "\n",
    "print('Casualties accuracy:',str(\"{:.2f}\".format(100*(negative_acc/negative_total)))+'%')\n",
    "print('Survival accuracy:',str(\"{:.2f}\".format(100*(positive_acc/positive_total)))+'%')\n",
    "print('Top model RF accuracy:',str(\"{:.2f}\".format(100*accuracy))+'%')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tree_preds = tree.predict(X_test)\n",
    "print('The accuracy of the Tree model is :\\t',metrics.accuracy_score(tree_preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create Tree Explainer object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(ensemble)\n",
    "\n",
    "# Evaluate SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_train, feature_names=encoded_dataset.feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Relation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values, X_train, feature_names=encoded_dataset.feature_names, plot_type=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
