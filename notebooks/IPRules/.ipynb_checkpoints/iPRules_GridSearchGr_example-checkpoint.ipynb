{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# iPRules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets._base import load_csv_data\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Dataset\n",
    "#iris\n",
    "#dataset = load_iris()\n",
    "target_value_name = 'class'\n",
    "\n",
    "# Mushrooms\n",
    "filename = 'mushrooms'\n",
    "target_true = 'p'\n",
    "target_false = 'e'\n",
    "test_size = 0.33\n",
    "\n",
    "\n",
    "data_file_name = f'../../data/{filename}.csv'\n",
    "pandas_dataset = pd.read_csv(data_file_name)\n",
    "\n",
    "pandas_dataset.columns = [sub.replace('%', '') for sub in pandas_dataset.columns]\n",
    "feature_names = pandas_dataset.columns[0:-1]\n",
    "target_value_name = pandas_dataset.columns[-1]\n",
    "\n",
    "pandas_dataset[target_value_name] = pandas_dataset[target_value_name].map({target_false:0,target_true:1})\n",
    "\n",
    "pandas_dataset.columns = [sub.replace(' ', '').replace('class', 'target_value') for sub in pandas_dataset.columns]\n",
    "target_value_name = pandas_dataset.columns[-1]\n",
    "\n",
    "#dataset.feature_names = [sub.replace(' ', '').replace('(cm)', '') for sub in dataset.feature_names]\n",
    "\n",
    "pandas_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# One Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = OneHotEncoder(sparse_output=False)\n",
    "encoded_array = enc.fit_transform(pandas_dataset.loc[:,feature_names])\n",
    "encoded_feature_names = enc.get_feature_names_out()\n",
    "df_encoded = pd.DataFrame(encoded_array,columns=encoded_feature_names)\n",
    "encoded_pandas_dataset = pd.concat([df_encoded, pandas_dataset],axis=1)\n",
    "encoded_pandas_dataset.drop(labels= feature_names,axis=1,inplace=True)\n",
    "encoded_pandas_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(pandas_dataset.shape)\n",
    "\n",
    "# One hot encoding + not doing anything in the rest\n",
    "#ct = make_column_transformer(\n",
    "#    (OneHotEncoder(), feature_names),\n",
    "#    n_jobs=3,\n",
    "#    remainder='passthrough',\n",
    "#    sparse_threshold=0)\n",
    "\n",
    "#pandas_dataset_encoded = ct.fit_transform(pandas_dataset).T\n",
    "\n",
    "#print(pandas_dataset_encoded[0])\n",
    "\n",
    "#column_names = (ct.named_transformers_[\"onehotencoder\"].get_feature_names_out().tolist()\n",
    "#               + [target_value_name])\n",
    "\n",
    "#encoded_dataset = pd.DataFrame(pandas_dataset_encoded, column_names)\n",
    "\n",
    "#encoded_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = encoded_pandas_dataset[encoded_feature_names]\n",
    "y = encoded_pandas_dataset[target_value_name]\n",
    "\n",
    "encoded_dataset = Bunch(\n",
    "        data=X.to_numpy(),\n",
    "        target=y.to_numpy(),\n",
    "        target_names=target_value_name,\n",
    "        feature_names=X.columns\n",
    ")\n",
    "\n",
    "#X_display = pandas_dataset.drop([target_value_name], axis=1)\n",
    "#y_display = pandas_dataset[target_value_name]\n",
    "\n",
    "#encoded_pandas_dataset = pd.DataFrame(data= np.c_[dataset['data'], dataset['target']], columns= dataset['feature_names'] + ['target'])\n",
    "#encoded_pandas_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Understand Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "encoded_pandas_dataset.plot(subplots=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(encoded_dataset.data, encoded_dataset.target, test_size=test_size, random_state=1)\n",
    "\n",
    "print('Sizes (without target):')\n",
    "print(f'Original size {encoded_dataset.data.shape}')\n",
    "print(f'Train size {X_train.shape}')\n",
    "print(f'Test size {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, make_scorer, recall_score, accuracy_score\n",
    "\n",
    "# Define scorer\n",
    "custom_scorer = make_scorer(accuracy_score, greater_is_better=True)\n",
    "param_grid = {\n",
    "        'n_estimators': [50, 100, 150, 200, 250, 300],  # being the number of trees in the forest.\n",
    "        'min_samples_leaf': [3], # number of minimum samples required at a leaf node.\n",
    "        'min_samples_split': [6], # number of minimum samples required to split an internal node.\n",
    "        'criterion': ['entropy','gini'], # measures the quality of a split. Can use gini's impurity or entropy.\n",
    "        }\n",
    "clf = GridSearchCV(\n",
    "        # Evaluates the performance of different groups of parameters for a model based on cross-validation.\n",
    "        RandomForestClassifier(),\n",
    "        param_grid,  # dict of parameters.\n",
    "        cv=10,  # Specified number of folds in the Cross-Validation(K-Fold).\n",
    "        scoring=custom_scorer)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "ensemble = clf.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "# Train the random forest classifier on the Iris dataset\n",
    "#ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions for the test set\n",
    "#y_pred_test = ensemble.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iPRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "from iPRules.iPRules import iPRules\n",
    "\n",
    "# initialize\n",
    "tree = iPRules(\n",
    "                base_ensemble=ensemble,\n",
    "                feature_names=encoded_dataset.feature_names,\n",
    "                target_value_name = target_value_name,\n",
    "                chi_square_probability = 0.95,\n",
    "                scale_feature_coefficient = 0.85\n",
    "            )\n",
    "\n",
    "# Fit model\n",
    "tree.fit(encoded_pandas_dataset, X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "tree_preds = tree.predict(X_test)\n",
    "print('The accuracy of the Tree model is :\\t',metrics.accuracy_score(tree_preds,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SHAP explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import shap\n",
    "\n",
    "# Create Tree Explainer object that can calculate shap values\n",
    "explainer = shap.TreeExplainer(ensemble)\n",
    "\n",
    "# Evaluate SHAP values\n",
    "shap_values = explainer.shap_values(X_test)\n",
    "shap.summary_plot(shap_values, X_train, feature_names=encoded_dataset.feature_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "shap.summary_plot(shap_values, X_train, feature_names=encoded_dataset.feature_names, plot_type=\"dot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
