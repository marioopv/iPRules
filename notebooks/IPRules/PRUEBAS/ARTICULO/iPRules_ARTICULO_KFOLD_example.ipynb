{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rules Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T18:23:41.230999Z",
     "end_time": "2023-04-25T18:23:43.961432Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.datasets._base import load_csv_data\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "from iPRules.iPRules import iPRules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from iPRules.iPRules import iPRules\n",
    "\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T18:23:43.965426Z",
     "end_time": "2023-04-25T18:23:44.020330Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   EMERGENCY_DIA_SHORT_F05  EMERGENCY_DIA_SHORT_J12  EMERGENCY_DIA_SHORT_R06  \\\n0                      0.0                      0.0                      0.0   \n1                      0.0                      0.0                      0.0   \n2                      0.0                      0.0                      0.0   \n3                      0.0                      0.0                      0.0   \n4                      0.0                      0.0                      0.0   \n\n   EMERGENCY_DIA_SHORT_K52  EMERGENCY_DIA_SHORT_I10  EMERGENCY_DIA_SHORT_J22  \\\n0                      0.0                      0.0                      0.0   \n1                      0.0                      0.0                      0.0   \n2                      0.0                      0.0                      0.0   \n3                      0.0                      0.0                      0.0   \n4                      0.0                      0.0                      0.0   \n\n   EMERGENCY_DIA_SHORT_J84  EMERGENCY_DIA_SHORT_E87  EMERGENCY_DIA_SHORT_R09  \\\n0                      0.0                      0.0                      0.0   \n1                      0.0                      0.0                      0.0   \n2                      0.0                      0.0                      0.0   \n3                      0.0                      0.0                      0.0   \n4                      0.0                      0.0                      0.0   \n\n   EMERGENCY_DIA_SHORT_J98  ...  ANTECEDENTS_PROC_BW03ZZZ  \\\n0                      0.0  ...                       1.0   \n1                      0.0  ...                       1.0   \n2                      0.0  ...                       1.0   \n3                      0.0  ...                       0.0   \n4                      0.0  ...                       1.0   \n\n   ANTECEDENTS_PROC_0TPBX0Z  ANTECEDENTS_PROC_F0796FZ  \\\n0                       0.0                       0.0   \n1                       0.0                       0.0   \n2                       0.0                       0.0   \n3                       0.0                       0.0   \n4                       0.0                       0.0   \n\n   ANTECEDENTS_PROC_4A12X4Z  ANTECEDENTS_PROC_3E03329  SEXO  AGE_LOWER_40  \\\n0                       0.0                       1.0     0             0   \n1                       0.0                       1.0     0             0   \n2                       0.0                       1.0     0             0   \n3                       0.0                       0.0     1             0   \n4                       0.0                       0.0     1             0   \n\n   AGE_40_60  AGE_HIGHER_60  RESULT  \n0          0              1       1  \n1          1              0       0  \n2          0              1       0  \n3          1              0       0  \n4          0              1       1  \n\n[5 rows x 120 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EMERGENCY_DIA_SHORT_F05</th>\n      <th>EMERGENCY_DIA_SHORT_J12</th>\n      <th>EMERGENCY_DIA_SHORT_R06</th>\n      <th>EMERGENCY_DIA_SHORT_K52</th>\n      <th>EMERGENCY_DIA_SHORT_I10</th>\n      <th>EMERGENCY_DIA_SHORT_J22</th>\n      <th>EMERGENCY_DIA_SHORT_J84</th>\n      <th>EMERGENCY_DIA_SHORT_E87</th>\n      <th>EMERGENCY_DIA_SHORT_R09</th>\n      <th>EMERGENCY_DIA_SHORT_J98</th>\n      <th>...</th>\n      <th>ANTECEDENTS_PROC_BW03ZZZ</th>\n      <th>ANTECEDENTS_PROC_0TPBX0Z</th>\n      <th>ANTECEDENTS_PROC_F0796FZ</th>\n      <th>ANTECEDENTS_PROC_4A12X4Z</th>\n      <th>ANTECEDENTS_PROC_3E03329</th>\n      <th>SEXO</th>\n      <th>AGE_LOWER_40</th>\n      <th>AGE_40_60</th>\n      <th>AGE_HIGHER_60</th>\n      <th>RESULT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 120 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Dataset\n",
    "target_true = '1'\n",
    "target_false = '0'\n",
    "test_size = 0.2\n",
    "filename = 'clean_dataset'\n",
    "\n",
    "\n",
    "\n",
    "data_file_name = f'../../../data/{filename}.csv'\n",
    "pandas_dataset = pd.read_csv(data_file_name)\n",
    "\n",
    "target_value_name = pandas_dataset.columns[-1]\n",
    "feature_names = pandas_dataset.columns[0:-1]\n",
    "\n",
    "pandas_dataset.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Divide dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T18:23:44.028805Z",
     "end_time": "2023-04-25T18:23:44.038710Z"
    }
   },
   "outputs": [],
   "source": [
    "X = pandas_dataset[feature_names]\n",
    "y = pandas_dataset[target_value_name]\n",
    "\n",
    "dataset = Bunch(\n",
    "        data=X.to_numpy(),\n",
    "        target=y.to_numpy(),\n",
    "        target_names=target_value_name,\n",
    "        feature_names=X.columns\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T18:23:44.038705Z",
     "end_time": "2023-04-25T18:23:44.266206Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import precision_score, make_scorer, recall_score, accuracy_score\n",
    "\n",
    "# Define scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iPRules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[82.28571428571428, 84.57142857142857, 80.57142857142857, 84.0, 57.47126436781609, 87.35632183908046, 59.77011494252874, 81.60919540229885, 67.24137931034483, 54.59770114942529]\n",
      "[0.9166666666666666, 0.8986486486486487, 0.8936170212765957, 0.9319727891156463, 0.95, 0.8881578947368421, 0.9711538461538461, 0.8591549295774648, 0.9658119658119658, 0.9894736842105263]\n",
      "[0.9097222222222222, 0.9054054054054054, 0.8936170212765957, 0.891156462585034, 0.95, 0.8881578947368421, 0.9615384615384616, 0.852112676056338, 0.9743589743589743, 0.9894736842105263]\n",
      "73.95 np_cobertura with a standard deviation of 12.07\n",
      "0.93 np_ensemble_accuracy with a standard deviation of 0.04\n",
      "0.92 np_rules_accuracy with a standard deviation of 0.04\n"
     ]
    }
   ],
   "source": [
    "n_splits = 10\n",
    "chi_square_percent_point_function = 0.95\n",
    "scale_feature_coefficient = 0.15\n",
    "min_accuracy_coefficient = 0.9\n",
    "min_number_class_per_node = 3\n",
    "sorting_method=\"target_accuracy\"\n",
    "criterion=\"entropy\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "cobertura_list = []\n",
    "ensemble_accuracy_list = []\n",
    "rules_accuracy_list = []\n",
    "\n",
    "for train, test in KFold(n_splits = 10).split(X, y):\n",
    "\n",
    "    ensemble = RandomForestClassifier(criterion=criterion)\n",
    "    X_train = X.loc[train].to_numpy()\n",
    "    y_train = y.loc[train].to_numpy()\n",
    "    X_test = X.loc[test].to_numpy()\n",
    "    y_test = y.loc[test].to_numpy()\n",
    "\n",
    "    encoded_train_pandas_dataset = pd.DataFrame(data= np.c_[X_train, y_train], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "    encoded_test_pandas_dataset = pd.DataFrame(data= np.c_[X_test, y_test], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "\n",
    "    rules = iPRules(\n",
    "                    feature_names=dataset.feature_names,\n",
    "                    target_value_name = dataset.target_names,\n",
    "                    chi_square_percent_point_function = chi_square_percent_point_function,\n",
    "                    scale_feature_coefficient = scale_feature_coefficient,\n",
    "                    min_accuracy_coefficient = min_accuracy_coefficient,\n",
    "                    min_number_class_per_node = min_number_class_per_node\n",
    "                )\n",
    "    # Fit model\n",
    "    ensemble.fit(X_train, y_train)\n",
    "    rules.fit(encoded_train_pandas_dataset, ensemble.feature_importances_)\n",
    "\n",
    "    # Predict\n",
    "    y_pred_test_ensemble = ensemble.predict(X_test)\n",
    "    y_pred_test_rules = rules.predict(X_test, sorting_method=sorting_method)\n",
    "\n",
    "    # Reduce Dataset\n",
    "    np_array_rules = np.array(y_pred_test_rules)\n",
    "    #not_filter_indices = np.where(np.logical_and(np_array_rules != 0, np_array_rules!=1))[0]\n",
    "    filter_indices = np.where(np_array_rules != None)[0]\n",
    "    np_filterred_y_test = np.array(y_test)[filter_indices]\n",
    "    np_filterred_y_pred_test_ensemble = np.array(y_pred_test_ensemble)[filter_indices]\n",
    "    np_filterred_y_pred_test_rules = np.array(y_pred_test_rules)[filter_indices].astype('int64')\n",
    "\n",
    "    # SCORERS\n",
    "    cobertura = len(np_filterred_y_pred_test_rules)/len(y_test)\n",
    "    cobertura_list.append(cobertura)\n",
    "\n",
    "    ensemble_accuracy = metrics.accuracy_score(np_filterred_y_test, np_filterred_y_pred_test_ensemble)\n",
    "    ensemble_accuracy_list.append(ensemble_accuracy)\n",
    "\n",
    "    rules_accuracy = metrics.accuracy_score(np_filterred_y_test, np_filterred_y_pred_test_rules)\n",
    "    rules_accuracy_list.append(rules_accuracy)\n",
    "\n",
    "\n",
    "np_cobertura = np.array(cobertura_list)\n",
    "np_ensemble_accuracy = np.array(ensemble_accuracy_list)\n",
    "np_rules_accuracy = np.array(rules_accuracy_list)\n",
    "\n",
    "print(\"%0.2f np_cobertura with a standard deviation of %0.2f\" % (np_cobertura.mean(), np_cobertura.std()))\n",
    "print(\"%0.2f np_ensemble_accuracy with a standard deviation of %0.2f\" % (np_ensemble_accuracy.mean(), np_ensemble_accuracy.std()))\n",
    "print(\"%0.2f np_rules_accuracy with a standard deviation of %0.2f\" % (np_rules_accuracy.mean(), np_rules_accuracy.std()))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-25T18:23:44.277121Z",
     "end_time": "2023-04-25T18:32:42.999451Z"
    }
   }
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
