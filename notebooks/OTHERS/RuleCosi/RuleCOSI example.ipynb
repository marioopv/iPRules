{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo of the combination and simplification algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T10:17:24.303774Z",
     "end_time": "2023-04-25T10:17:25.673291Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For using the library, just import the _RuleCOSIClassifier_ class from **rulecosi** package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The algorithm works with several type of tree ensembles and it uses the **sklearn** implementations.\n",
    "- Bagging Trees\n",
    "- RandomForests\n",
    "- Gradient Boosting Trees (original implementation)\n",
    "- XGBoost\n",
    "- Light GBM\n",
    "- CatBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T10:17:25.675813Z",
     "end_time": "2023-04-25T10:17:28.873493Z"
    }
   },
   "outputs": [],
   "source": [
    "#from catboost import CatBoostClassifier\n",
    "#from lightgbm import LGBMClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "#from sklearn.ensemble import BaggingClassifier, RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.utils import Bunch\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load a sample dataset and split the data\n",
    "\n",
    "We use the Wisconsin diagnostic breast cancer dataset. There are two classes, malignant (0) and benign (1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T10:17:28.875671Z",
     "end_time": "2023-04-25T10:17:28.916029Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "   EMERGENCY_DIA_SHORT_F05  EMERGENCY_DIA_SHORT_J12  EMERGENCY_DIA_SHORT_R06  \\\n0                      0.0                      0.0                      0.0   \n1                      0.0                      0.0                      0.0   \n2                      0.0                      0.0                      0.0   \n3                      0.0                      0.0                      0.0   \n4                      0.0                      0.0                      0.0   \n\n   EMERGENCY_DIA_SHORT_K52  EMERGENCY_DIA_SHORT_I10  EMERGENCY_DIA_SHORT_J22  \\\n0                      0.0                      0.0                      0.0   \n1                      0.0                      0.0                      0.0   \n2                      0.0                      0.0                      0.0   \n3                      0.0                      0.0                      0.0   \n4                      0.0                      0.0                      0.0   \n\n   EMERGENCY_DIA_SHORT_J84  EMERGENCY_DIA_SHORT_E87  EMERGENCY_DIA_SHORT_R09  \\\n0                      0.0                      0.0                      0.0   \n1                      0.0                      0.0                      0.0   \n2                      0.0                      0.0                      0.0   \n3                      0.0                      0.0                      0.0   \n4                      0.0                      0.0                      0.0   \n\n   EMERGENCY_DIA_SHORT_J98  ...  ANTECEDENTS_PROC_BW03ZZZ  \\\n0                      0.0  ...                       1.0   \n1                      0.0  ...                       1.0   \n2                      0.0  ...                       1.0   \n3                      0.0  ...                       0.0   \n4                      0.0  ...                       1.0   \n\n   ANTECEDENTS_PROC_0TPBX0Z  ANTECEDENTS_PROC_F0796FZ  \\\n0                       0.0                       0.0   \n1                       0.0                       0.0   \n2                       0.0                       0.0   \n3                       0.0                       0.0   \n4                       0.0                       0.0   \n\n   ANTECEDENTS_PROC_4A12X4Z  ANTECEDENTS_PROC_3E03329  SEXO  AGE_LOWER_40  \\\n0                       0.0                       1.0     0             0   \n1                       0.0                       1.0     0             0   \n2                       0.0                       1.0     0             0   \n3                       0.0                       0.0     1             0   \n4                       0.0                       0.0     1             0   \n\n   AGE_40_60  AGE_HIGHER_60  RESULT  \n0          0              1       1  \n1          1              0       0  \n2          0              1       0  \n3          1              0       0  \n4          0              1       1  \n\n[5 rows x 120 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>EMERGENCY_DIA_SHORT_F05</th>\n      <th>EMERGENCY_DIA_SHORT_J12</th>\n      <th>EMERGENCY_DIA_SHORT_R06</th>\n      <th>EMERGENCY_DIA_SHORT_K52</th>\n      <th>EMERGENCY_DIA_SHORT_I10</th>\n      <th>EMERGENCY_DIA_SHORT_J22</th>\n      <th>EMERGENCY_DIA_SHORT_J84</th>\n      <th>EMERGENCY_DIA_SHORT_E87</th>\n      <th>EMERGENCY_DIA_SHORT_R09</th>\n      <th>EMERGENCY_DIA_SHORT_J98</th>\n      <th>...</th>\n      <th>ANTECEDENTS_PROC_BW03ZZZ</th>\n      <th>ANTECEDENTS_PROC_0TPBX0Z</th>\n      <th>ANTECEDENTS_PROC_F0796FZ</th>\n      <th>ANTECEDENTS_PROC_4A12X4Z</th>\n      <th>ANTECEDENTS_PROC_3E03329</th>\n      <th>SEXO</th>\n      <th>AGE_LOWER_40</th>\n      <th>AGE_40_60</th>\n      <th>AGE_HIGHER_60</th>\n      <th>RESULT</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows Ã— 120 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "test_size = 0.2\n",
    "filename = 'clean_dataset'\n",
    "\n",
    "\n",
    "\n",
    "data_file_name = f'../../data/{filename}.csv'\n",
    "pandas_dataset = pd.read_csv(data_file_name)\n",
    "\n",
    "target_value_name = pandas_dataset.columns[-1]\n",
    "feature_names = pandas_dataset.columns[0:-1]\n",
    "\n",
    "pandas_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T10:17:28.921117Z",
     "end_time": "2023-04-25T10:17:28.927755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sizes (without target):\n",
      "Original size (1744, 119)\n",
      "Train size (1395, 119)\n",
      "Test size (349, 119)\n"
     ]
    }
   ],
   "source": [
    "X = pandas_dataset[feature_names]\n",
    "y = pandas_dataset[target_value_name]\n",
    "\n",
    "dataset = Bunch(\n",
    "        data=X.to_numpy(),\n",
    "        target=y.to_numpy(),\n",
    "        target_names=target_value_name,\n",
    "        feature_names=X.columns\n",
    ")\n",
    "\n",
    "#Define dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset.data, dataset.target, test_size=test_size, random_state=1)\n",
    "encoded_train_pandas_dataset = pd.DataFrame(data= np.c_[X_train, y_train], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "encoded_test_pandas_dataset = pd.DataFrame(data= np.c_[X_test, y_test], columns= list(dataset['feature_names']) + [target_value_name])\n",
    "print()\n",
    "print('Sizes (without target):')\n",
    "print(f'Original size {dataset.data.shape}')\n",
    "print(f'Train size {X_train.shape}')\n",
    "print(f'Test size {X_test.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simplifying an XGBoost classifier\n",
    "\n",
    "We create a XGBClassifier instance. The ensemble can be fitted, or it can be just instantiated and RuleCOSI will fit the ensemble first and then simplify it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-25T10:17:28.930618Z",
     "end_time": "2023-04-25T10:17:28.932339Z"
    }
   },
   "outputs": [],
   "source": [
    "ens = XGBClassifier(random_state=1212)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is done by instanciating a **RuleCOSIClassifier** class with the desired parameters, _n\\_estimator_, _tree\\_max\\_depth_, _conf\\_threshold_ and _min\\_samples_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-19T13:40:44.557446Z",
     "end_time": "2023-04-19T13:40:44.570876Z"
    }
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (/Users/mpv/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/charset_normalizer/constant.py)",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/requests/compat.py:11\u001B[0m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mchardet\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'chardet'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[0;31mImportError\u001B[0m                               Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mnotebooks\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mRuleCosi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrulecosi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrulecosi\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01m_rulecosi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RuleCOSIClassifier\n\u001B[1;32m      3\u001B[0m rc \u001B[38;5;241m=\u001B[39m RuleCOSIClassifier(base_ensemble\u001B[38;5;241m=\u001B[39mens,\n\u001B[1;32m      4\u001B[0m                         metric\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mf1\u001B[39m\u001B[38;5;124m'\u001B[39m,n_estimators\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m100\u001B[39m, tree_max_depth\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m, \n\u001B[1;32m      5\u001B[0m                         conf_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.9\u001B[39m, cov_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0\u001B[39m,\n\u001B[1;32m      6\u001B[0m                         random_state\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1212\u001B[39m, column_names\u001B[38;5;241m=\u001B[39mdataset\u001B[38;5;241m.\u001B[39mfeature_names)\n",
      "File \u001B[0;32m~/Documents/GitHub/Projects/iPRules/notebooks/RuleCosi/rulecosi/rulecosi/_rulecosi.py:31\u001B[0m\n\u001B[1;32m     28\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[1;32m     30\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mst\u001B[39;00m\n\u001B[0;32m---> 31\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RuleSet, Rule\n\u001B[1;32m     33\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BaseEstimator, ClassifierMixin\n\u001B[1;32m     34\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbase\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m clone, is_classifier, is_regressor\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/imodels/__init__.py:10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscretization\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscretizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RFDiscretizer, BasicDiscretizer\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdiscretization\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmdlp\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m MDLPDiscretizer, BRLDiscretizer\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexperimental\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbartpy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BART\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrule_list\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian_rule_list\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mbayesian_rule_list\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BayesianRuleListClassifier\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mrule_list\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcorels_wrapper\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m OptimalRuleListClassifier\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/imodels/experimental/bartpy/__init__.py:1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msklearnmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m BART, ShrunkBART, ShrunkBARTCV\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/imodels/experimental/bartpy/sklearnmodel.py:18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Data\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minitializers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minitializer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Initializer\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodel\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Model\n\u001B[1;32m     19\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mnode\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LeafNode, DecisionNode\n\u001B[1;32m     20\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msamplers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mleafnode\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m LeafNodeSampler\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/imodels/experimental/bartpy/model.py:10\u001B[0m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Data\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minitializers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minitializer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Initializer\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01minitializers\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msklearntreeinitializer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m SklearnTreeInitializer\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msigma\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Sigma\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msplit\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Split\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/imodels/experimental/bartpy/initializers/sklearntreeinitializer.py:6\u001B[0m\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mensemble\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m GradientBoostingRegressor, RandomForestRegressor\n\u001B[0;32m----> 6\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mfigs\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m FIGSRegressor, Node, FIGSRegressorCV\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m NotFittedError\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m DecisionTreeRegressor\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/imodels/tree/figs.py:18\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mtree\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mviz_utils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m extract_sklearn_tree_from_figs\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01marguments\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m check_fit_arguments\n\u001B[0;32m---> 18\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mimodels\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutil\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdata_util\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m encode_categories\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mNode\u001B[39;00m:\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__init__\u001B[39m(\u001B[38;5;28mself\u001B[39m, feature: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, threshold: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     23\u001B[0m                  value\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, value_sklearn\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, idxs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, is_root: \u001B[38;5;28mbool\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mFalse\u001B[39;00m, left\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     24\u001B[0m                  impurity: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, impurity_reduction: \u001B[38;5;28mfloat\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, tree_num: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m, node_id: \u001B[38;5;28mint\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[1;32m     25\u001B[0m                  right\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/imodels/util/data_util.py:7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mpandas\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mpd\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mrequests\u001B[39;00m\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msklearn\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mdatasets\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01msparse\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m issparse\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/requests/__init__.py:45\u001B[0m\n\u001B[1;32m     41\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m\n\u001B[1;32m     43\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01murllib3\u001B[39;00m\n\u001B[0;32m---> 45\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m RequestsDependencyWarning\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__ \u001B[38;5;28;01mas\u001B[39;00m charset_normalizer_version\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/requests/exceptions.py:9\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03mrequests.exceptions\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m~~~~~~~~~~~~~~~~~~~\u001B[39;00m\n\u001B[1;32m      4\u001B[0m \n\u001B[1;32m      5\u001B[0m \u001B[38;5;124;03mThis module contains the set of Requests' exceptions.\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01murllib3\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mexceptions\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m HTTPError \u001B[38;5;28;01mas\u001B[39;00m BaseHTTPError\n\u001B[0;32m----> 9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mcompat\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m JSONDecodeError \u001B[38;5;28;01mas\u001B[39;00m CompatJSONDecodeError\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mRequestException\u001B[39;00m(\u001B[38;5;167;01mIOError\u001B[39;00m):\n\u001B[1;32m     13\u001B[0m     \u001B[38;5;124;03m\"\"\"There was an ambiguous exception that occurred while handling your\u001B[39;00m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;124;03m    request.\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/requests/compat.py:13\u001B[0m\n\u001B[1;32m     11\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mchardet\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mImportError\u001B[39;00m:\n\u001B[0;32m---> 13\u001B[0m     \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mchardet\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01msys\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;66;03m# -------\u001B[39;00m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Pythons\u001B[39;00m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# -------\u001B[39;00m\n\u001B[1;32m     20\u001B[0m \n\u001B[1;32m     21\u001B[0m \u001B[38;5;66;03m# Syntax sugar.\u001B[39;00m\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/charset_normalizer/__init__.py:23\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;124;03mCharset-Normalizer\u001B[39;00m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;124;03m~~~~~~~~~~~~~~\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;124;03m:license: MIT, see LICENSE for more details.\u001B[39;00m\n\u001B[1;32m     22\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m---> 23\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mapi\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m from_fp, from_path, from_bytes, normalize\n\u001B[1;32m     24\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mlegacy\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m detect\n\u001B[1;32m     25\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mversion\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m __version__, VERSION\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/charset_normalizer/api.py:10\u001B[0m\n\u001B[1;32m      7\u001B[0m     PathLike \u001B[38;5;241m=\u001B[39m Union[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mos.PathLike[str]\u001B[39m\u001B[38;5;124m'\u001B[39m]  \u001B[38;5;66;03m# type: ignore\u001B[39;00m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstant\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m TOO_SMALL_SEQUENCE, TOO_BIG_SEQUENCE, IANA_SUPPORTED\n\u001B[0;32m---> 10\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmd\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m mess_ratio\n\u001B[1;32m     11\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mmodels\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m CharsetMatches, CharsetMatch\n\u001B[1;32m     12\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mwarnings\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m warn\n",
      "File \u001B[0;32m~/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/charset_normalizer/md.py:5\u001B[0m\n\u001B[1;32m      2\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mtyping\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Optional, List\n\u001B[1;32m      4\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mconstant\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m UNICODE_SECONDARY_RANGE_KEYWORD\n\u001B[0;32m----> 5\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mcharset_normalizer\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mutils\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m is_punctuation, is_symbol, unicode_range, is_accentuated, is_latin, \\\n\u001B[1;32m      6\u001B[0m     remove_accent, is_separator, is_cjk, is_case_variable, is_hangul, is_katakana, is_hiragana, is_ascii, is_thai\n\u001B[1;32m      9\u001B[0m \u001B[38;5;28;01mclass\u001B[39;00m \u001B[38;5;21;01mMessDetectorPlugin\u001B[39;00m:\n\u001B[1;32m     10\u001B[0m     \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m     11\u001B[0m \u001B[38;5;124;03m    Base abstract class used for mess detection plugins.\u001B[39;00m\n\u001B[1;32m     12\u001B[0m \u001B[38;5;124;03m    All detectors MUST extend and implement given methods.\u001B[39;00m\n\u001B[1;32m     13\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n",
      "\u001B[0;31mImportError\u001B[0m: cannot import name 'COMMON_SAFE_ASCII_CHARACTERS' from 'charset_normalizer.constant' (/Users/mpv/opt/anaconda3/envs/iPRules/lib/python3.10/site-packages/charset_normalizer/constant.py)"
     ]
    }
   ],
   "source": [
    "\n",
    "from notebooks.RuleCosi.rulecosi.rulecosi._rulecosi import RuleCOSIClassifier\n",
    "\n",
    "rc = RuleCOSIClassifier(base_ensemble=ens,\n",
    "                        metric='f1',n_estimators=100, tree_max_depth=3, \n",
    "                        conf_threshold=0.9, cov_threshold=0.0,\n",
    "                        random_state=1212, column_names=dataset.feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "rc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining the simplified rules\n",
    "\n",
    "The rules will be stored in the _simplified\\_ruleset_ \\_ attribute of the RuleCOSI object. The function _print\\_rules_ print the rules and its heuristics on the console. It can also return a string object or a pandas DataFrame object to be used for further analysis. Additionally, the decimal digits displayed on the heuristics values and the condition thresholds can be modified with the _heuristics\\_digits_ and the _condition\\_digits_ parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.simplified_ruleset_.print_rules(heuristics_digits=4, condition_digits=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc.simplified_ruleset_.print_rules(return_object='dataframe',heuristics_digits=4, condition_digits=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking the classification performance of the simplified rule-based classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function is used for counting the number of rules extracted from the tree ensemble (original ruelesets)\n",
    "def get_n_rules(rulesets):\n",
    "    n_rules = 0\n",
    "    for ruleset in rulesets:\n",
    "        for rule in ruleset:\n",
    "            n_rules += 1\n",
    "    return n_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'== Original XGBoost ensemble ==')\n",
    "print(f'Number of trees: {rc.base_ensemble_.n_estimators} trees')\n",
    "print(f'Number of rules: {get_n_rules(rc.original_rulesets_)} rules\\n')\n",
    "\n",
    "print(f'== Simplified rules ==')\n",
    "rc.simplified_ruleset_.print_rules()\n",
    "y_pred = rc.predict(X_test)\n",
    "if isinstance(rc.base_ensemble, XGBClassifier):\n",
    "    y_pred_ens = rc.base_ensemble_.predict(X_test, validate_features=False)\n",
    "else:\n",
    "    y_pred_ens = rc.base_ensemble_.predict(X_test)\n",
    "print(\"Combinations: {}\".format(rc.n_combinations_))\n",
    "print(\"Time: {}\\n\".format(rc.combination_time_))\n",
    "print(f'====== Classification performance of XGBoost ======')\n",
    "print(classification_report(y_test, y_pred_ens,digits=4))\n",
    "print(f'\\n====== Classification performance of simplified rules ======')\n",
    "print(classification_report(y_test, y_pred,digits=4))\n",
    "print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
